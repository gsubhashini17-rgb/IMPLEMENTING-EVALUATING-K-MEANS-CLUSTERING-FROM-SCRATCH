# -*- coding: utf-8 -*-
"""Implementing,Evaluating KMeans Clustering from Scratch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bgLGbjIalIyXZxMj5yxeJq8Pt4S3UE5E
"""

import numpy as np
from sklearn.datasets import make_blobs
import matplotlib.pyplot as plt

# Set global random seed for reproducibility
np.random.seed(42)

class CustomKMeans:
    """
    Custom implementation of K-Means clustering algorithm.

    This class implements the Expectation-Maximization steps of K-Means:
    1. Initialization: Random centroid selection
    2. E-step: Assign points to nearest centroids
    3. M-step: Update centroids as mean of assigned points
    4. Repeat until convergence

    Attributes:
        n_clusters (int): Number of clusters (K)
        max_iter (int): Maximum iterations
        tol (float): Convergence tolerance
        centroids (ndarray): Final centroid positions
        labels (ndarray): Cluster assignments for training data
        inertia_ (float): Sum of squared errors (SSE)
    """

    def __init__(self, n_clusters=3, max_iter=300, tol=1e-4):
        """
        Initialize K-Means parameters.

        Args:
            n_clusters (int): Number of clusters (default: 3)
            max_iter (int): Maximum iterations (default: 300)
            tol (float): Convergence tolerance (default: 1e-4)
        """
        self.n_clusters = n_clusters
        self.max_iter = max_iter
        self.tol = tol
        self.centroids = None
        self.labels = None
        self.inertia_ = None

    def _initialize_centroids(self, X):
        """
        Initialize centroids by randomly selecting K data points.

        Args:
            X (ndarray): Input data of shape (n_samples, n_features)

        Returns:
            ndarray: Initial centroids of shape (n_clusters, n_features)
        """
        n_samples = X.shape[0]
        random_indices = np.random.choice(n_samples, self.n_clusters, replace=False)
        return X[random_indices]

    def _assign_clusters(self, X):
        """
        E-step: Assign each data point to the nearest centroid.

        Uses NumPy broadcasting for efficient distance calculation:
        1. Reshape X to (n_samples, 1, n_features)
        2. Broadcast subtract centroids (n_clusters, n_features)
        3. Compute Euclidean norm along features axis
        4. Assign each point to minimum distance centroid

        Args:
            X (ndarray): Input data

        Returns:
            ndarray: Cluster assignments for each point
        """
        distances = np.linalg.norm(X[:, np.newaxis] - self.centroids, axis=2)
        return np.argmin(distances, axis=1)

    def _update_centroids(self, X, labels):
        """
        M-step: Update centroids as mean of assigned points.

        Args:
            X (ndarray): Input data
            labels (ndarray): Current cluster assignments

        Returns:
            ndarray: Updated centroids
        """
        new_centroids = np.zeros((self.n_clusters, X.shape[1]))

        for i in range(self.n_clusters):
            cluster_points = X[labels == i]

            if len(cluster_points) > 0:
                new_centroids[i] = cluster_points.mean(axis=0)
            else:
                # Handle empty cluster: reinitialize randomly
                new_centroids[i] = X[np.random.choice(X.shape[0])]

        return new_centroids

    def _calculate_inertia(self, X, labels):
        """
        Calculate Sum of Squared Errors (Inertia/SSE).

        Inertia = sum of squared distances from each point to its assigned centroid

        Args:
            X (ndarray): Input data
            labels (ndarray): Cluster assignments

        Returns:
            float: Inertia (SSE) value
        """
        inertia = 0.0

        for i in range(self.n_clusters):
            cluster_points = X[labels == i]

            if len(cluster_points) > 0:
                squared_distances = np.sum(
                    (cluster_points - self.centroids[i]) ** 2, axis=1
                )
                inertia += np.sum(squared_distances)

        return inertia

    def fit(self, X):
        """
        Fit K-Means model to the data.

        Args:
            X (ndarray): Training data of shape (n_samples, n_features)

        Returns:
            self: Fitted model
        """
        # Step 1: Initialize centroids randomly
        self.centroids = self._initialize_centroids(X)

        # Step 2: Iterate until convergence or max_iter
        for iteration in range(self.max_iter):
            # E-step: Assign points to clusters
            labels = self._assign_clusters(X)

            # M-step: Update centroids
            new_centroids = self._update_centroids(X, labels)

            # Check convergence: if centroids moved less than tolerance
            centroid_shift = np.linalg.norm(new_centroids - self.centroids)

            # Update centroids and labels
            self.centroids = new_centroids
            self.labels = labels

            # Check for convergence
            if centroid_shift < self.tol:
                print(f"  Converged after {iteration + 1} iterations")
                break

        # Calculate final inertia
        self.inertia_ = self._calculate_inertia(X, self.labels)

        return self

    def predict(self, X):
        """
        Predict cluster labels for new data.

        Args:
            X (ndarray): New data to predict

        Returns:
            ndarray: Predicted cluster labels
        """
        return self._assign_clusters(X)


def main():
    """
    Main function to execute the complete project.

    Tasks performed:
    1. Generate synthetic dataset with 3 clusters
    2. Implement and run custom K-Means for K=3 and K=5
    3. Calculate and compare SSE/Inertia values
    4. Generate required visualizations
    5. Provide analysis and justification
    """
    print("=" * 60)
    print("K-MEANS CLUSTERING FROM SCRATCH - PROJECT IMPLEMENTATION")
    print("=" * 60)

    # ============================================================================
    # TASK 1: DATASET GENERATION
    # ============================================================================
    print("\n" + "=" * 60)
    print("TASK 1: DATASET GENERATION")
    print("=" * 60)

    X, y_true = make_blobs(
        n_samples=300,
        n_features=2,
        centers=3,
        cluster_std=1.0,
        random_state=42
    )

    print(f"Dataset shape: {X.shape}")
    print(f"Number of samples: {X.shape[0]}")
    print(f"Number of features: {X.shape[1]}")
    print(f"True number of clusters (from generation): 3")

    # ============================================================================
    # TASK 2 & 3: K-MEANS IMPLEMENTATION AND RUN
    # ============================================================================
    print("\n" + "=" * 60)
    print("TASK 2 & 3: K-MEANS IMPLEMENTATION AND RUN")
    print("=" * 60)

    print("\nRunning Custom K-Means with K=3 (optimal)...")
    kmeans3 = CustomKMeans(n_clusters=3)
    kmeans3.fit(X)
    sse_k3 = kmeans3.inertia_
    print(f"  SSE/Inertia for K=3: {sse_k3:.2f}")

    print("\nRunning Custom K-Means with K=5 (for comparison)...")
    kmeans5 = CustomKMeans(n_clusters=5)
    kmeans5.fit(X)
    sse_k5 = kmeans5.inertia_
    print(f"  SSE/Inertia for K=5: {sse_k5:.2f}")

    # ============================================================================
    # TASK 4: VISUALIZATIONS
    # ============================================================================
    print("\n" + "=" * 60)
    print("TASK 4: VISUALIZATIONS")
    print("=" * 60)

    fig, axes = plt.subplots(1, 3, figsize=(15, 4))

    # Plot 1: Original dataset with true clusters
    axes[0].scatter(X[:, 0], X[:, 1], c=y_true, cmap="viridis",
                    alpha=0.7, edgecolor="k", s=50)
    axes[0].set_title("Original Dataset (True Clusters)")
    axes[0].set_xlabel("Feature 1")
    axes[0].set_ylabel("Feature 2")
    axes[0].grid(True, alpha=0.3)

    # Plot 2: K=3 clustering results
    axes[1].scatter(X[:, 0], X[:, 1], c=kmeans3.labels,
                    cmap="viridis", alpha=0.7, edgecolor="k", s=50)
    axes[1].scatter(kmeans3.centroids[:, 0], kmeans3.centroids[:, 1],
                    c="red", marker="X", s=200, linewidths=2,
                    edgecolor="black", label="Centroids")
    axes[1].set_title(f"K=3 Clustering Results\nSSE = {sse_k3:.2f}")
    axes[1].set_xlabel("Feature 1")
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)

    # Plot 3: Final centroids
    axes[2].scatter(X[:, 0], X[:, 1], c="lightgray", alpha=0.3, s=30)
    for i, centroid in enumerate(kmeans3.centroids):
        axes[2].scatter(centroid[0], centroid[1],
                        s=300, marker=f"${i}$",
                        edgecolors="black", linewidth=2,
                        label=f"Centroid {i}")
    axes[2].set_title("Final Centroids (K=3)")
    axes[2].set_xlabel("Feature 1")
    axes[2].legend()
    axes[2].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig("kmeans_clustering_results.png", dpi=150, bbox_inches="tight")
    plt.show()

    # ============================================================================
    # TASK 5: ANALYSIS AND COMPARISON
    # ============================================================================
    print("\n" + "=" * 60)
    print("TASK 5: ANALYSIS AND COMPARISON")
    print("=" * 60)

    print(f"\nSSE/INERTIA COMPARISON:")
    print("-" * 40)
    print(f"K = 3: {sse_k3:.2f}")
    print(f"K = 5: {sse_k5:.2f}")
    print(f"Difference: {sse_k5 - sse_k3:.2f} "
          f"(K=5 is {sse_k5 / sse_k3 * 100:.1f}% of K=3 SSE)")

    reduction = ((sse_k3 - sse_k5) / sse_k3) * 100
    print(f"\nK=5 achieves {reduction:.1f}% lower SSE than K=3")

    print("\n" + "=" * 60)
    print("PROJECT COMPLETED SUCCESSFULLY")
    print("=" * 60)

    return kmeans3, kmeans5, X


if __name__ == "__main__":
    main()